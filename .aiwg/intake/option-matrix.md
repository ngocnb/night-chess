# Option Matrix (Project Context & Intent)

**Purpose**: Capture what this project IS — its nature, audience, constraints, and intent — to determine appropriate SDLC framework application (templates, commands, agents, rigor levels).

**Generated**: 2026-02-27

---

## Step 1: Project Reality

### What IS This Project?

**Project Description**:
```
Night Chess is a web-based chess puzzle platform built on the open Lichess puzzle database
(3.5M+ puzzles, public domain). V1 delivers a FastAPI (Python) backend and Next.js frontend
where guests can instantly solve random puzzles and registered users save their progress.
V2 adds Flutter mobile apps (Android + iOS) reusing the same backend.
```

### Audience & Scale

**Who uses this?**
- [ ] Just me (personal project)
- [ ] Small team (2-10 people, known individuals)
- [x] External customers (100–10k users, paying or free) — public chess enthusiasts
- [ ] Large scale (10k–100k+ users) — not yet; revisit at scale

**Audience Characteristics**:
- Technical sophistication: Mixed (chess enthusiasts from casual to competitive; not necessarily technical)
- User risk tolerance: Expects stability (users will drop off if puzzles fail to load)
- Support expectations: Self-service (no support SLA for MVP; help docs sufficient)

**Usage Scale**:
- Active users: 500 initially; 5,000 in 6 months; 20,000+ in 2 years (chess community growth)
- Request volume: ~20–50 requests/min at launch; ~500/min at 5k active users
- Data volume: ~800 MB puzzle database (PostgreSQL); <1 GB user progress data for first year
- Geographic distribution: Global (chess is international); no geo-specific infra required for MVP

### Deployment & Infrastructure

**Expected Deployment Model**:
- [x] Client-server (Next.js frontend + FastAPI backend, separate services)
- [ ] Serverless (Lambda/Cloud Functions) — not appropriate for stateful FastAPI + PostgreSQL
- [ ] Mobile — v2 only (Flutter)
- [ ] Microservices — overkill for current scale

**Where does this run?**
- [x] Cloud platform (AWS or Render for managed simplicity)
- [ ] On-premise
- [ ] Local only

**Infrastructure Complexity**:
- Deployment type: Multi-tier (Next.js frontend + FastAPI API + PostgreSQL database)
- Data persistence: Single database (PostgreSQL) with large initial dataset (3.5M puzzles)
- External dependencies: 1 (Lichess puzzle database download — no API key, bulk import only)
- Network topology: Client-server (browser → Next.js → FastAPI → PostgreSQL)

### Technical Complexity

**Codebase Characteristics** (estimated):
- Size: 10k–30k LoC (FastAPI REST API + Next.js app with chessboard UI)
- Languages: Python (backend), TypeScript (frontend), Dart (mobile v2)
- Architecture: Separated client-server (two services, shared PostgreSQL)
- Team familiarity: Greenfield (new project, specified stack)

**Technical Risk Factors**:
- [x] Performance-sensitive — Random puzzle selection from 3.5M rows needs optimization
- [x] Security-sensitive — User authentication (JWT, password hashing, session management)
- [x] Data integrity-critical — Lichess import must preserve puzzle accuracy (FEN + solution moves)
- [ ] High concurrency — Not a risk at MVP scale
- [x] Complex business logic — Chess move validation (legal move checking, puzzle completion detection)
- [ ] Integration-heavy — Only one external integration (Lichess data download)

---

## Step 2: Constraints & Context

### Resources

**Team**:
- Size: 1–3 developers (full-stack capable)
- Experience: Mid-level (Python + TypeScript proficiency assumed from tech stack choices)
- Availability: Full-time or part-time (not specified; assume 1–2 full-time equivalents)

**Budget**:
- Development: Moderate (small team, open source tools throughout)
- Infrastructure: $20–$100/month (Render or AWS free tier + RDS) — cost-conscious
- Timeline: 8–14 weeks to v1 web launch (inferred from MVP scope)

### Regulatory & Compliance

**Data Sensitivity**:
- [x] User-provided content (email, profile preferences)
- [x] Personally Identifiable Information (PII: email address, password hash)
- [ ] Payment information — not applicable
- [ ] Protected Health Information — not applicable

**Regulatory Requirements**:
- [x] GDPR — if serving EU users (email = PII; account deletion right applies)
- [ ] CCPA — not primary target market for MVP
- [ ] HIPAA — not applicable
- [ ] PCI-DSS — not applicable (no payment processing)
- [ ] SOC2 / SOX — not required for MVP

**Contractual Obligations**:
- [x] None (no contracts, no SLA commitments for MVP)
- [ ] SLA — add post-MVP when user base grows or partnerships form

### Technical Context

**Current State**:
- Stage: Planning — no application code written yet
- Test coverage: Target 50% overall, 80% for critical paths
- Documentation: README (to create), OpenAPI spec (auto-generated by FastAPI)
- Deployment automation: Docker Compose (local) + GitHub Actions (CI/CD) + cloud deploy

---

## Step 3: Priorities & Trade-offs

### What Matters Most?

**Priority Ranking** (1 = most important):
1. Quality/security (auth correctness + data pipeline integrity cannot be compromised)
2. Delivery speed (chess puzzle market is active; launch fast to validate)
3. Reliability/scale (99% uptime sufficient for MVP; scale later)
4. Cost efficiency (open source data + modest infrastructure keeps costs low)

**Priority Weights**:

| Criterion | Weight | Rationale |
|-----------|--------|-----------|
| **Delivery speed** | 0.30 | Fast validation of product-market fit; web MVP first before Flutter investment |
| **Cost efficiency** | 0.20 | Small team, open source data, cloud-managed services keep costs predictable |
| **Quality/security** | 0.30 | Auth system + data pipeline carry real risk; correctness is non-negotiable |
| **Reliability/scale** | 0.20 | 99% uptime sufficient for MVP; Redis + scaling deferred until proven demand |
| **TOTAL** | **1.00** | ← Balanced MVP profile |

### Trade-off Context

**What are you optimizing for?**
```
Fast delivery of a focused, high-quality puzzle experience to validate chess enthusiast demand.
The Lichess puzzle dataset is the core differentiator — the platform's value is curation and
UX simplicity, not feature breadth. Ship v1 (web) quickly, validate engagement, then invest
in Flutter mobile (v2).
```

**What are you willing to sacrifice?**
```
- Advanced features (puzzle themes, spaced repetition, social features) — deferred post-MVP
- Perfect test coverage (50% overall is MVP-acceptable; 80% on critical paths)
- Enterprise-grade monitoring (Sentry + structured logs sufficient for MVP)
- Manual deployment steps acceptable if CI/CD setup takes too long initially
```

**What is non-negotiable?**
```
- Puzzle data accuracy: FEN positions and solution moves must be imported correctly from Lichess
- Authentication security: Passwords must be properly hashed (bcrypt); JWT tokens must be short-lived
- Data integrity: User progress must be reliably saved and retrieved
- Chess rules correctness: Move validation must be accurate (no illegal moves accepted as solutions)
```

---

## Step 4: Intent & Decision Context

### Why This Intake Now?

**What triggered this intake?**
- [x] Starting new project (need to plan approach — AIWG SDLC framework installed, ready to begin)
- [x] Seeking SDLC structure (multi-agent framework activated; intake is entry point)

**What decisions need making?**
```
1. Deployment architecture: Single server vs separate frontend/backend deployments
2. Puzzle selection algorithm: Simple RANDOM() vs pre-batched random pool vs rating-weighted sampling
3. Authentication approach: JWT only vs session-based vs OAuth (social login)
4. Chess rendering library: react-chessboard vs chessground vs custom SVG
5. Data pipeline strategy: One-time bulk import vs periodic sync vs streaming
```

**What's uncertain or controversial?**
```
- Scale inflection point: Unclear when random puzzle selection becomes a performance bottleneck
  (3.5M rows, RANDOM() scan) — need to prototype early
- Flutter timeline: V2 mobile scope is undefined; need to ensure FastAPI API design is
  mobile-friendly from day one (versioned endpoints, appropriate response schemas)
```

**Success criteria for this intake process**:
```
Clear technical direction for v1 web app delivery. Architecture decisions documented.
Team (or solo developer) can start Sprint 1 immediately with no open architectural questions.
```

---

## Step 5: Framework Application

### Relevant SDLC Components

**Templates** (applicable):
- [x] Intake (project-intake, solution-profile, option-matrix) — **Active**
- [x] Requirements (user stories) — Include: useful for 2+ developer coordination and tracking feature scope
- [x] Architecture (ADRs) — Include: 3+ key decisions (tech stack, auth, puzzle rendering, data pipeline)
- [x] Test (test strategy, test cases) — Include: critical paths need test plans (auth + data pipeline)
- [x] Security (threat model — lightweight) — Include: auth + PII warrants basic threat assessment
- [ ] Governance (decision-log, RACI) — **Skip**: team too small, informal coordination sufficient
- [ ] Deployment runbook (formal) — **Skip**: deployment section in README is sufficient for MVP

**Commands** (applicable):
- [x] `/intake-wizard`, `/intake-start` — Active (this intake)
- [x] `/flow-concept-to-inception` — Next step after intake review
- [x] `/flow-inception-to-elaboration` — After architecture decisions are locked
- [x] `/flow-guided-implementation` — During construction phase
- [x] `/pr-review` — Code review for quality gates
- [x] `/build-poc` — Recommend for Lichess data pipeline prototype (high-risk component)
- [ ] `/flow-compliance-validation` — Skip: no compliance requirements for MVP
- [ ] `/flow-hypercare-monitoring` — Skip: post-launch, not needed for MVP

**Agents** (applicable):
- [x] `requirements-analyst` — User stories for auth, puzzle fetch, progress tracking
- [x] `architecture-designer` — FastAPI + Next.js + PostgreSQL component design
- [x] `software-implementer` — Core feature implementation
- [x] `test-engineer` — pytest + Jest test suite design
- [x] `code-reviewer` — PR review for quality and security
- [x] `devops-engineer` — Docker Compose + GitHub Actions + cloud deploy
- [x] `security-auditor` — Auth implementation review (JWT, bcrypt, input validation)
- [ ] `legal-liaison` — Skip: no contracts or compliance for MVP
- [ ] `reliability-engineer` — Skip: 99% uptime doesn't require SRE formalism for MVP
- [ ] `privacy-officer` — Add when GDPR controls are implemented

**Process Rigor Level**: Moderate
- Intake ✓ (this document set)
- User stories for v1 features
- ADRs for key decisions
- Basic test strategy
- README + OpenAPI (auto-generated)

### Rationale for Framework Choices

**Why this subset?**
```
MVP project (8–14 week timeline, 1–3 developers) needs Moderate rigor:

INCLUDE:
- Intake (establish baseline, align on architecture)
- User stories (coordinate v1 feature delivery across small team)
- ADRs (3–5 key decisions to document: auth approach, puzzle algo, rendering lib)
- Test strategy (critical paths: auth + data pipeline are high-risk)
- Lightweight security review (JWT auth + PII warrants basic threat assessment)

SKIP:
- Governance templates (team of 1–3, informal coordination sufficient)
- Formal deployment runbook (README section is sufficient)
- SOC2/compliance controls (no regulatory requirements)
- Formal SLO/SLI tracking (99% uptime, no SLA contracts)
```

**What we're skipping and why**:
```
Skipping enterprise and compliance templates because:
- No regulatory requirements (HIPAA, PCI-DSS, SOC2 not applicable)
- Small team (1–3 developers, no coordination overhead)
- MVP timeline (8–14 weeks, lightweight process priority)
- External users but no SLA contracts or compliance certifications

Will revisit if:
- User base exceeds 5,000 registered users (→ Production profile)
- EU marketing campaign begins (→ GDPR controls required)
- Flutter v2 requires API versioning governance
- Team expands to 5+ people (→ add governance templates)
```

---

## Step 6: Evolution & Adaptation

### Expected Changes

**How might this project evolve?**
- [x] User base growth (when: 3–6 months, trigger: successful v1 launch + community sharing)
- [x] Feature expansion (when: post-v1, trigger: user engagement validated; puzzle filtering, streaks)
- [x] Mobile app (when: 4–8 months post-v1, trigger: v1 stability + Flutter investment justified)
- [ ] Team expansion (when: if project monetizes or grows significantly)
- [x] Compliance requirements (when: EU marketing, trigger: GDPR controls needed)
- [ ] Technical pivot (not expected — FastAPI + Next.js is well-suited for this domain)

**Adaptation Triggers**:
```
Add security templates when:
- GDPR account deletion + privacy policy required (pre-EU-launch)
- Payment processing considered (→ PCI-DSS controls)

Add governance templates when:
- Team exceeds 3–5 people
- Flutter v2 development begins (API contract governance important)

Upgrade to Production profile when:
- 500+ registered users with real progress data
- 99.9% uptime commitment desired
- Monitoring needs APM (Datadog/New Relic) beyond Sentry

Upgrade to Enterprise profile when:
- Compliance certification required (SOC2)
- Contracts with partners/schools requiring SLAs
```

**Planned Framework Evolution**:
- **Now (Inception)**: Intake + user stories + ADRs + basic test strategy
- **3 months (Construction)**: Add deployment docs + data pipeline runbook + security review
- **6 months (Transition)**: Add GDPR controls + 99.9% uptime monitoring + Flutter API governance
- **12 months (Production profile)**: APM monitoring + formal test strategy + performance testing

---

## Architectural Options Analysis

### Option A: Separate FastAPI + Next.js (Recommended)

**Description**: FastAPI backend (Python) deployed as a standalone REST API service. Next.js frontend deployed separately (Vercel or cloud), calling FastAPI for data. PostgreSQL managed database. This is the specified architecture.

**Technology Stack**:
- Backend: Python 3.12, FastAPI, SQLAlchemy, Alembic, PostgreSQL
- Frontend: Next.js 14 (App Router), TypeScript, react-chessboard, chess.js
- Database: PostgreSQL 16 (managed — AWS RDS or Render)
- CI/CD: GitHub Actions
- Deploy: Render (backend + DB) + Vercel (frontend) OR AWS EC2/ECS + RDS + CloudFront

**Scoring** (0–5 scale):

| Criterion | Score | Rationale |
|-----------|------:|-----------|
| Delivery Speed | 4 | Well-understood stack; FastAPI + Next.js have excellent DX; Render/Vercel enable fast deploy |
| Cost Efficiency | 4 | Managed services eliminate infra overhead; Render free tier + Vercel free tier for MVP |
| Quality/Security | 4 | FastAPI Pydantic validation; TypeScript type safety; JWT/bcrypt well-supported |
| Reliability/Scale | 4 | Scales independently (frontend on CDN, backend horizontally); PostgreSQL scales to millions of rows |
| **Weighted Total** | **4.00** | (4×0.30) + (4×0.20) + (4×0.30) + (4×0.20) = 4.00 |

**Trade-offs**:
- **Pros**: Specified by team; clean separation enables Flutter v2 reuse of backend; Next.js + Vercel = excellent SSR/caching for puzzle pages; FastAPI auto-generates OpenAPI spec
- **Cons**: Two deployment targets to manage; CORS configuration required between frontend and backend

**When to choose**: Always — this is the specified architecture. Validates for both web (v1) and mobile (v2).

---

### Option B: Full-Stack Next.js with API Routes

**Description**: Use Next.js API routes for backend logic (no separate FastAPI service). Database access directly from Next.js server-side functions via Prisma or Drizzle ORM. Deploy as single Next.js application to Vercel.

**Technology Stack**:
- Full-stack: Next.js 14 (App Router + API routes), TypeScript, Prisma, PostgreSQL
- Deploy: Vercel (full-stack)
- Chess: react-chessboard + chess.js (same as Option A frontend)

**Scoring** (0–5 scale):

| Criterion | Score | Rationale |
|-----------|------:|-----------|
| Delivery Speed | 5 | Single codebase, no CORS config, Vercel handles everything |
| Cost Efficiency | 5 | Single Vercel deployment; no separate backend hosting cost |
| Quality/Security | 3 | No FastAPI Pydantic validation; TypeScript types partially compensate; Python ecosystem loses |
| Reliability/Scale | 3 | Next.js API routes are serverless; cold starts; not suitable for Flutter mobile API |
| **Weighted Total** | **3.90** | (5×0.30) + (5×0.20) + (3×0.30) + (3×0.20) = 3.90 |

**Trade-offs**:
- **Pros**: Simplest deployment; no CORS; Vercel free tier covers both frontend and backend
- **Cons**: Cannot reuse for Flutter v2 (mobile needs standalone REST API); no Python ecosystem (lichess data import tooling is Python-first); serverless cold starts hurt puzzle fetch latency; diverges from stated requirements

**When to choose**: Only if Flutter v2 is cancelled AND team prefers TypeScript-only stack. Does not meet stated requirements.

---

### Option C: Microservices (FastAPI + Next.js + Separate Data Import Service)

**Description**: Three distinct services: (1) FastAPI puzzle API, (2) Next.js frontend, (3) Standalone Python data import worker for periodic Lichess database sync. Event-driven architecture with PostgreSQL as shared data store.

**Technology Stack**:
- API: FastAPI + PostgreSQL (same as Option A)
- Frontend: Next.js + Vercel (same as Option A)
- Data Worker: Standalone Python service (scheduled via cron or event trigger)
- Orchestration: Docker Compose (local) + Kubernetes or ECS (production)

**Scoring** (0–5 scale):

| Criterion | Score | Rationale |
|-----------|------:|-----------|
| Delivery Speed | 2 | Three services to build and coordinate; Kubernetes overhead not justified for MVP |
| Cost Efficiency | 2 | Higher infra cost; three running services vs two |
| Quality/Security | 4 | Clean separation; data pipeline isolated from API (failure isolation) |
| Reliability/Scale | 5 | Independent scaling; data pipeline failures don't affect API; production-ready pattern |
| **Weighted Total** | **3.10** | (2×0.30) + (2×0.20) + (4×0.30) + (5×0.20) = 3.10 |

**Trade-offs**:
- **Pros**: Clean separation of data pipeline from API; data worker can be re-run without API downtime; scales to enterprise patterns
- **Cons**: Overkill for MVP scale; complex local dev setup; Kubernetes not justified until >10k users; slows initial delivery significantly

**When to choose**: Revisit at Production profile (>5k users) when periodic Lichess database syncs become a requirement. Not appropriate for MVP.

---

## Recommendation

**Recommended Option**: Option A — Separate FastAPI + Next.js (Score: 4.00)

**Rationale**: Option A matches the stated tech stack, delivers the highest balanced score across all priorities, enables Flutter v2 mobile reuse of the FastAPI backend, and is deployable quickly via Render + Vercel. Option B is faster to deploy but diverges from requirements and blocks v2 mobile. Option C is the right long-term architecture but adds delivery overhead that isn't justified for MVP scale.

**Sensitivities**:
- If Flutter v2 is cancelled → Option B becomes viable (TypeScript-only stack simplification)
- If timeline becomes extremely tight (< 6 weeks) → Option B for fastest initial delivery, migrate to Option A before v2
- If user base exceeds 10k and data pipeline needs periodic refresh → Option C (extract data worker as separate service)

**Implementation Plan**:
1. Initialize FastAPI project (Python 3.12, FastAPI, SQLAlchemy, Alembic, PostgreSQL)
2. Initialize Next.js project (TypeScript, App Router, react-chessboard, chess.js)
3. Prototype data import script (download lichess `.zst`, decompress, parse CSV, bulk insert via `COPY`)
4. Implement database schema (migrations with Alembic)
5. Build auth endpoints (register, login, refresh, logout) + JWT middleware
6. Build puzzle API (random puzzle, submit result)
7. Build progress API (save, retrieve history)
8. Build Next.js chessboard component + puzzle flow
9. Build auth UI + protected progress dashboard
10. Deploy to staging (Render + Vercel); integration test; launch

**Risks and Mitigations**:
- **Risk 1**: `ORDER BY RANDOM()` on 3.5M puzzles is slow (full table scan) → Mitigation: pre-generate random puzzle ID pool via background job; cache batch in Redis; or use PostgreSQL TABLESAMPLE SYSTEM for approximate random selection
- **Risk 2**: Lichess CSV schema changes between downloads → Mitigation: validate expected column names at import start; pin to known schema version; log warnings on schema mismatch
- **Risk 3**: Chess move validation complexity (en passant, castling, promotion, checkmate detection) → Mitigation: use `chess.js` (battle-tested, 1M+ weekly npm downloads) for all move validation; do not implement custom chess rules
- **Risk 4**: Flutter v2 API compatibility → Mitigation: design FastAPI endpoints with versioning from day one (`/api/v1/`); keep response schemas clean and documented via OpenAPI

---

## Next Steps

1. Review option-matrix and confirm Option A (FastAPI + Next.js) is the agreed architecture
2. Confirm priority weights align with team/stakeholder expectations
3. Schedule PoC sprint for Lichess data pipeline (highest technical risk item)
4. Start Inception flow: `/flow-concept-to-inception .`
5. Create ADRs for: (1) auth approach (JWT), (2) puzzle rendering library, (3) random puzzle algorithm
6. Revisit framework selection at first phase gate (Inception → Elaboration)
